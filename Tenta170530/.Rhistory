logRicePostGrid[count] <-log.post(riceData, theta, v)
}
logRicePostGrid
exp(logRicePostGrid)
plot(gridWidth, exp(logRicePostGrid))
install.packages("mvtnorm")
install.packages("Bessel")
library(Bessel)
#compute log posterior
# Since we don't have any information about the prior we assuem it to be constant. Ex 1 => log(constant) = constant
# when normalazing this all vlues will be affected equally hence it does not make any difference
log.post = function(theta, x, v){
log_like = sum(log(x/v)*(-(x^2+theta^2)) + log(besselI(x*theta/v, 0))) + 2
return(log_like)
}
riceData <- c(1.556, 1.861, 3.135, 1.311, 1.877, 0.622, 3.219, 0.768, 2.358, 2.056)
sequence = seq(0.1, 5, 0.1)
theta = 1
v = 1
prior = 1
# Plot the posterior over a grid of theta values. Gives us the probability depending on different theta values
gridWidth <- 0.01
thetaGrid <- seq(0.01, 3, by = gridWidth)
logRicePostGrid <- rep(0,length(thetaGrid))
count <- 0
for (theta in thetaGrid){
count <- count + 1
logRicePostGrid[count] <-log.post(theta, riceData, v)
}
posterior = exp(logRicePostGrid)
posterior_normalized = (1/gridWidth)*posterior/(sum(posterior))
plot(posterior_normalized)
#b) Normal approximation of the posterior distr. of theta
# Different starting values. Ideally, any random starting value gives you the same optimum (i.e. optimum is unique)
initVal <- c(1);
# function which optmizes over expression log.posterior with respect to its first argument (betas).
# returns optimal values for beta (mode), and hessian in the mode
OptParams<-optim(initVal,log.post,gr=NULL,riceData, v ,method=c("L-BFGS-B"),lower = 0, control=list(fnscale=-1),hessian=TRUE)
my_posterior = OptParams$par
# takes negative so that the posterior can be approx. as normal
# J = -second derivate evaluated in theta_hat
hessian_posterior = -OptParams$hessian
# take inverse for using it in the formula
hessian_posterior = (solve(hessian_posterior))
sigma = sqrt(hessian_posterior[1,1])
#Draw samples from Betas posterior distribution.
set.seed(12345)
#We now have a posterior distributin which is ~N(my_posterior, sigma_square). We want to do the same thing as before
# plot the pdf over a grid of values => Since we have it in a good form we can do it immedeatly and directly get
# the normalized values
approximate_density_distribution = dnorm(thetaGrid, mean = my_posterior, sd = sigma)
plot(thetaGrid, posterior_normalized)
lines(thetaGrid, approximate_density_distribution, col = "red", type ="b")
#C)
#1. Explain on paper how the predictive distribution for a new observation is ocmputed by integration. Only
#The general dormula
#2. Compute the predictive distribution for a new observation by simulation. USe the approximate posterior from b
# simulator for r_rice is given by exam file
rRice <-function(n = 1, theta = 1, psi = 1){
x <- rnorm(n = n, mean = 0, sd = sqrt(psi))
y <- rnorm(n = n, mean = theta, sd = sqrt(psi))
return(sqrt(x^2+y^2))
}
#Draw from the posterior distribution and use these draws to plug in and make draw from test data
outcome =c()
set.seed(12345)
for (i in 1:1000){
#nake draw from posterior distr.
theta_draw = rnorm(n = 1, mean = my_posterior, sd = sigma)
#plug in draw and make fraw from predictions distr.
rice = rRice(1,theta_draw,1)
outcome = append(outcome, rice)
}
#Histrogram of the predictive
hist(outcome, main="Predictive distribution x_tilde", xlab="rice", ylab="Acumulation of rice out of 1000 draws")
#Assignemnt 2
# eBay bids data
load(file = 'bids.RData')    # Loading the vector 'bids' into workspace
bids = bids
bidsCounts <- table(bids)  # data2Counts is a frequency table of counts.
xGrid <- seq(min(bids),max(bids))  # A grid used as input to GibbsMixPois.R over which the mixture density is evaluated.
#a
#Copute the posterior distribution for theta and plot it => the posterior pdf
n = auctions = length(bids)
alpha = 1
beta = 1
amount_bids = sum(bids)
#Posterior parameters for gamma distriution
alpha_posterior = amount_bids + alpha
beta_posterior = n + beta
#Plot the posterior distribution for theta (gamma funktion)
# => draws from gamma density distribution over a seequence of different values
gamma_grid = seq(3.4,3.9, length = 1000)
plot(gamma_grid, dgamma(gamma_grid, alpha_posterior, beta_posterior), xlab = "Theta", ylab = "Density")
#b
#Does the poisson model describe the distribution of the data well ?
#=> Model evaluation => Make draws from the posterior of theta. Use these to plug in
# to the distribution of the data (in this casepossion) and make new replica draws
data_density = density(bids)
plot(data_density)
xGrid = seq(min(bids),max(bids))
#Manually create the density of the data
#Normalize
data_dens = bidsCounts/sum(bidsCounts)
plot(xGrid, data_dens, type = 'l')
#Make repliica draws using draws from posterior
set.seed(12345)
theta_draw = rgamma(1000, alpha_posterior, beta_posterior)
#For each draw theta we want to compute the possion distribution (distribution for
# x values)
density_mean = rep(0,12)
for (i in 1:n){
#Compute poission distribution over Xgrid = över de x värden vi vill distribuera
# proba
density_mean = density_mean + dpois(xGrid, theta_draw[i])
}
#Make a T function (condition) that we can compare with the original data. in this
#case we compute the mean density for each grid value
density_mean = density_mean/n
plot(xGrid, data_dens, type = 'l' )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,20) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,1) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.01) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.08) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.1) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.5) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.3) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
lines(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
nDraws = 1000
thetaDraws = rgamma(n = nDraws, shape = alphaGamma + sum(bids), rate = betaGamma + n)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraws[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
thetaDraws = rgamma(n = nDraws, shape = alphaGamma + sum(bids), rate = betaGamma + n)
thetaDraws = rgamma(n = nDraws, shape = alpha_posterior, rate = beta_posterior)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraws[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
length(xGrid)
xGrid
density_mean = rep(0,13)
for (i in 1:n){
#Compute poission distribution over Xgrid = över de x värden vi vill distribuera
# proba
density_mean = density_mean + dpois(xGrid, theta_draw[i])
}
#Make a T function (condition) that we can compare with the original data. in this
#case we compute the mean density for each grid value
density_mean = density_mean/n
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
lines(density_mean)
density_mean = rep(0,13)
for (i in 1:n){
#Compute poission distribution over Xgrid = över de x värden vi vill distribuera
# proba
density_mean = density_mean + dpois(xGrid, theta_draw[i])
}
#Make a T function (condition) that we can compare with the original data. in this
#case we compute the mean density for each grid value
density_mean = density_mean/n
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
lines(density_mean)
density_mean = rep(0,13)
density_mean
PoisDensMean <- rep(0, length(xGrid))
PoisDensMean
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
nDraws = 1000
thetaDraws = rgamma(n = nDraws, shape = alpha_posterior, rate = beta_posterior)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraws[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
nDraws = 1000
thetaDraws = rgamma(n = nDraws, shape = alpha_posterior, rate = beta_posterior)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraws[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
nDraws = 1000
thetaDraws = rgamma(n = nDraws, shape = alpha_posterior, rate = beta_posterior)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraws[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
lines(density_mean)
nDraws = 1000
thetaDraws = rgamma(n = nDraws, shape = alpha_posterior, rate = beta_posterior)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraws[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
lines(density_mean)
plot(density_mean)
nDraws = 1000
set.seed(12345)
theta_draw = rgamma(nDraws, shape = lpha_posterior, rate = beta_posterior)
#For each draw theta we want to compute the possion distribution (distribution for
# x values)
density_mean = rep(0, length(xGrid))
for (i in 1:n){
#Compute poission distribution over Xgrid = över de x värden vi vill distribuera
# proba
density_mean = density_mean + dpois(xGrid, theta_draw[i])
}
#Make a T function (condition) that we can compare with the original data. in this
#case we compute the mean density for each grid value
density_mean = density_mean/n
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
plot(density_mean)
plot(density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
plot(density_mean)
nDraws = 1000
set.seed(12345)
theta_draw = rgamma(nDraws, shape = alpha_posterior, rate = beta_posterior)
#For each draw theta we want to compute the possion distribution (distribution for
# x values)
density_mean = rep(0, length(xGrid))
for (i in 1:n){
#Compute poission distribution over Xgrid = över de x värden vi vill distribuera
# proba
density_mean = density_mean + dpois(xGrid, theta_draw[i])
}
#Make a T function (condition) that we can compare with the original data. in this
#case we compute the mean density for each grid value
density_mean = density_mean/n
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
plot(density_mean)
nDraws = 1000
thetaDraws = rgamma(n = nDraws, shape = alpha_posterior, rate = beta_posterior)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraw[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
nDraws = 1000
thetaDraws = rgamma(n = nDraws, shape = alpha_posterior, rate = beta_posterior)
PoisDensMean <- rep(0, length(xGrid))
for (i in 1:nDraws){
PoisDensMean = PoisDensMean + dpois(xGrid, lambda = thetaDraws[i])
}
PoisDensMean = PoisDensMean/nDraws # Average
lines(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
plot(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
plot(xGrid, density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
plot(xGrid, density_mean)
plot(xGrid, data_dens, type = 'l', ylim = c(0,0.2) )
lines(xGrid, density_mean)
plot(xGrid, PoisDensMean, type = "o", lwd = 1, col = "blue", pch = 'o', cex = 0.6)
plot(xGrid, density_mean, type = 'l', ylim = c(0,0.2) )
plot(xGrid, density_mean, type = 'l', ylim = c(0,0.2), type = "o")
plot(xGrid, density_mean, type = 'l', ylim = c(0,0.2), type = "o")
plot(xGrid, density_mean, type = 'l', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'l', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'b', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'p', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'l', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2))
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'p')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'l')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'p')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', cex = 0.6)
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', cex = 0.8)
lines(data_dens)
lines(xGrid, data_dens)
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', cex = 0.8)
lines(xGrid, data_dens)
plot(xGrid, density_mean, type = 'o', lwd = 1, ylim = c(0,0.2), pch = 'o', cex = 0.8)
plot(xGrid, density_mean, type = 'o', lwd = 1, ylim = c(0,0.2), pch = 'o', cex = 0.8)
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', cex = 0.8)
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', cex = 0.8)
lines(xGrid, data_dens, col = "red")
lines(xGrid, data_dens, col = "red", type = 'b')
lines(xGrid, data_dens, col = "red", type = 'b', pch = 'o')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', cex = 0.8)
lines(xGrid, data_dens, col = "red", type = 'b', pch = 'o')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o')
lines(xGrid, data_dens, col = "red", type = 'b', pch = 'o')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', xlab = "bids")
lines(xGrid, data_dens, col = "red", type = 'b', pch = 'o')
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', xlab = "bids", ylab = "density")
lines(xGrid, data_dens, col = "red", type = 'b', pch = 'o')
# eBay bids data
load(file = 'bids.RData')    # Loading the vector 'bids' into workspace
bidsCounts <- table(bids)  # data2Counts is a frequency table of counts.
xGrid <- seq(min(bids),max(bids))  # A grid used as input to GibbsMixPois.R over which the mixture density is evaluated.
# Code for Problem 3 - Exam in Bayesian Learning 2017-05-30
GibbsMixPois <- function(x, nComp, alpha, alphaGamma, betaGamma, xGrid, nIter){
# Gibbs sampling for a mixture of Poissons
# Author: Mattias Villani, IDA, Linkoping University. http://mattiasvillani.com
#
# INPUTS:
#   x - vector with data observations (counts)
#   nComp - Number of mixture components to be fitted
#   alpha - The prior on the mixture component weights is w ~ Dir(alpha, alpha,..., alpha)
#   alphaGamma and betaGamma -
#              The prior on the mean (theta) of the Poisson mixture components is
#              theta ~ Gamma(alphaGamma, betaGamma) [rate parametrization of the Gamma dist]
#   xGrid - the grid of data values over which the mixture is evaluated and plotted
#   nIter - Number of Gibbs iterations
#
# OUTPUTS:
#   results$wSample     - Gibbs sample of mixture component weights. nIter-by-nComp matrix
#   results$thetaSample - Gibbs sample of mixture component means.   nIter-by-nComp matrix
#   results$mixDensMean - Posterior mean of the estimated mixture density over xGrid.
####### Defining a function that simulates from a Dirichlet distribution
rDirichlet <- function(param){
nCat <- length(param)
thetaDraws <- matrix(NA,nCat,1)
for (j in 1:nCat){
thetaDraws[j] <- rgamma(1,param[j],1)
}
thetaDraws = thetaDraws/sum(thetaDraws) # Diving every column of ThetaDraws by the sum of the elements in that column.
return(thetaDraws)
}
# Simple function that converts between two different representations of the mixture allocation
S2alloc <- function(S){
n <- dim(S)[1]
alloc <- rep(0,n)
for (i in 1:n){
alloc[i] <- which(S[i,] == 1)
}
return(alloc)
}
# Initial values for the Gibbs sampling
nObs <- length(x)
S <- t(rmultinom(nObs, size = 1 , prob = rep(1/nComp,nComp))) # nObs-by-nComp matrix with component allocations.
theta <- rep(mean(x), nComp) # Each component is initialized at the mean of the data
# Setting up the grid where the mixture density is evaluated.
mixDensMean <- rep(0,length(xGrid))
effIterCount <- 0
# Setting up matrices to store the draws
wSample <- matrix(0, nIter, nComp)
thetaSample <- matrix(0, nIter, nComp)
probObsInComp <- rep(NA, nComp)
# Setting up the priors - the same prior for all components
alpha <- rep(alpha, nComp)
alphaGamma <- rep(alphaGamma, nComp)
betaGamma <- rep(betaGamma, nComp)
# HERE STARTS THE ACTUAL GIBBS SAMPLING
for (k in 1:nIter){
message(paste('Iteration number:',k))
alloc <- S2alloc(S) # Function that converts between different representations of the group allocations
nAlloc <- colSums(S)
# Step 1 - Update components probabilities
w <- rDirichlet(alpha + nAlloc)
wSample[k,] <- w
# Step 2 - Update theta's in Poisson components
for (j in 1:nComp){
theta[j] <- rgamma(1, shape = alphaGamma + sum(x[alloc == j]), rate = betaGamma + nAlloc[j])
}
thetaSample[k,] <- theta
# Step 3 - Update allocation
for (i in 1:nObs){
for (j in 1:nComp){
probObsInComp[j] <- w[j]*dpois(x[i], lambda = theta[j])
}
S[i,] <- t(rmultinom(1, size = 1 , prob = probObsInComp/sum(probObsInComp)))
}
# Computing the mixture density at the current parameters, and averaging that over draws.
effIterCount <- effIterCount + 1
mixDens <- rep(0,length(xGrid))
for (j in 1:nComp){
compDens <- dpois(xGrid, lambda = theta[j])
mixDens <- mixDens + w[j]*compDens
}
mixDensMean <- ((effIterCount-1)*mixDensMean + mixDens)/effIterCount
}
return(results = list(wSample = wSample, thetaSample = thetaSample, mixDensMean = mixDensMean))
}
# eBay bids data
load(file = 'bids.RData')    # Loading the vector 'bids' into workspace
bidsCounts <- table(bids)  # data2Counts is a frequency table of counts.
xGrid <- seq(min(bids),max(bids))  # A grid used as input to GibbsMixPois.R over which the mixture density is evaluated.
# Code for Problem 3 - Exam in Bayesian Learning 2017-05-30
GibbsMixPois <- function(x, nComp, alpha, alphaGamma, betaGamma, xGrid, nIter){
# Gibbs sampling for a mixture of Poissons
# Author: Mattias Villani, IDA, Linkoping University. http://mattiasvillani.com
#
# INPUTS:
#   x - vector with data observations (counts)
#   nComp - Number of mixture components to be fitted
#   alpha - The prior on the mixture component weights is w ~ Dir(alpha, alpha,..., alpha)
#   alphaGamma and betaGamma -
#              The prior on the mean (theta) of the Poisson mixture components is
#              theta ~ Gamma(alphaGamma, betaGamma) [rate parametrization of the Gamma dist]
#   xGrid - the grid of data values over which the mixture is evaluated and plotted
#   nIter - Number of Gibbs iterations
#
# OUTPUTS:
#   results$wSample     - Gibbs sample of mixture component weights. nIter-by-nComp matrix
#   results$thetaSample - Gibbs sample of mixture component means.   nIter-by-nComp matrix
#   results$mixDensMean - Posterior mean of the estimated mixture density over xGrid.
####### Defining a function that simulates from a Dirichlet distribution
rDirichlet <- function(param){
nCat <- length(param)
thetaDraws <- matrix(NA,nCat,1)
for (j in 1:nCat){
thetaDraws[j] <- rgamma(1,param[j],1)
}
thetaDraws = thetaDraws/sum(thetaDraws) # Diving every column of ThetaDraws by the sum of the elements in that column.
return(thetaDraws)
}
# Simple function that converts between two different representations of the mixture allocation
S2alloc <- function(S){
n <- dim(S)[1]
alloc <- rep(0,n)
for (i in 1:n){
alloc[i] <- which(S[i,] == 1)
}
return(alloc)
}
# Initial values for the Gibbs sampling
nObs <- length(x)
S <- t(rmultinom(nObs, size = 1 , prob = rep(1/nComp,nComp))) # nObs-by-nComp matrix with component allocations.
theta <- rep(mean(x), nComp) # Each component is initialized at the mean of the data
# Setting up the grid where the mixture density is evaluated.
mixDensMean <- rep(0,length(xGrid))
effIterCount <- 0
# Setting up matrices to store the draws
wSample <- matrix(0, nIter, nComp)
thetaSample <- matrix(0, nIter, nComp)
probObsInComp <- rep(NA, nComp)
# Setting up the priors - the same prior for all components
alpha <- rep(alpha, nComp)
alphaGamma <- rep(alphaGamma, nComp)
betaGamma <- rep(betaGamma, nComp)
# HERE STARTS THE ACTUAL GIBBS SAMPLING
for (k in 1:nIter){
message(paste('Iteration number:',k))
alloc <- S2alloc(S) # Function that converts between different representations of the group allocations
nAlloc <- colSums(S)
# Step 1 - Update components probabilities
w <- rDirichlet(alpha + nAlloc)
wSample[k,] <- w
# Step 2 - Update theta's in Poisson components
for (j in 1:nComp){
theta[j] <- rgamma(1, shape = alphaGamma + sum(x[alloc == j]), rate = betaGamma + nAlloc[j])
}
thetaSample[k,] <- theta
# Step 3 - Update allocation
for (i in 1:nObs){
for (j in 1:nComp){
probObsInComp[j] <- w[j]*dpois(x[i], lambda = theta[j])
}
S[i,] <- t(rmultinom(1, size = 1 , prob = probObsInComp/sum(probObsInComp)))
}
# Computing the mixture density at the current parameters, and averaging that over draws.
effIterCount <- effIterCount + 1
mixDens <- rep(0,length(xGrid))
for (j in 1:nComp){
compDens <- dpois(xGrid, lambda = theta[j])
mixDens <- mixDens + w[j]*compDens
}
mixDensMean <- ((effIterCount-1)*mixDensMean + mixDens)/effIterCount
}
return(results = list(wSample = wSample, thetaSample = thetaSample, mixDensMean = mixDensMean))
}
mixed
p = GibbsMixPois(bids, 2, alpha, alpha_posterior, beta_posterior, xGrid, 500)
p
p = GibbsMixPois(bids, 2, alpha, alpha_posterior, beta_posterior, xGrid, 500)
p$mixDensMean
p$mixDensMean
lines(p$mixDensMean)
p = GibbsMixPois(bids, 2, alpha, alpha_posterior, beta_posterior, xGrid, 500)p
p
p$wSample
p = GibbsMixPois(bids, 2, alpha, alpha, beta, xGrid, 500)
p$mixDensMean
lines(p$mixDensMean)
plot(xGrid, density_mean, type = 'o', ylim = c(0,0.2), pch = 'o', xlab = "bids", ylab = "density")
lines(xGrid, data_dens, col = "red", type = 'b', pch = 'o')
lines(xGrid, p$mixDensMean)
p = GibbsMixPois(bids, 3, alpha, alpha, beta, xGrid, 500)
p$mixDensMean
lines(xGrid, p$mixDensMean)
